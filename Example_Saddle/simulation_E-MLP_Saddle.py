#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Jan 27 20:09:20 2022

simulate the series by conditional distribution of sigma'

@author: dliu
"""

import sys 
sys.path.append("..") 
import torch
import numpy as np
import matplotlib.pyplot as plt

from utils import get_dataset
from misc import parameters

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# params = parameters(data_type='Saddle_high', n_trainset=20, kx=1, ks=10, x_lower_bound=-1, lr=5e-4)
params = parameters(data_type='Saddle_low', n_trainset=20, kx=1, ks=10, x_lower_bound=-1, lr=5e-4)


data_test_pathes = params.data_pathes[params.n_trainset:params.n_trainset+1]

### load data
x_lower_bound = params.x_lower_bound
kx = params.kx
ks = params.ks
x1, x2, s1, s2, diff_x, diff_s, dt_x, dt_s = \
    get_dataset(data_test_pathes, x_lower_bound=x_lower_bound, kx=kx, ks=ks, resample=False)


### load model for ODE(x and sigma)
from model import model_f_saddle
model_f = model_f_saddle().to(device)
model_f.load_state_dict(torch.load(params.model_f_path))

### load model for std and mean
from model import model_std_mean_saddle
model_H = model_std_mean_saddle().to(device)
model_H.load_state_dict(torch.load(params.model_std_mean_path))

### load model for distribution of noise in sigma
from model import model_fs_dist_saddle
model_K = model_fs_dist_saddle().to(device)
model_K.load_state_dict(torch.load(params.model_dist_path))


def plot_x_s(t_series, x_series, s_series):
    plt.figure(figsize=[16,5])
    plt.subplot(1,2,1)
    plt.plot(t_series, x_series, linewidth=.6)#, label='$X$ generated by Euler method')
    plt.xlabel('t')
    plt.title('Generated $X$')
    # plt.plot(x1[:10000], label='x real')
    plt.subplot(1,2,2)
    plt.plot(t_series, s_series, linewidth=.6)#, label=r'$\bar{\sigma}$ generated by Euler method')
    plt.xlabel('t')
    # plt.legend()
    plt.title(r'Generated $\bar{\sigma}$')
    # plt.savefig('./figures/Saddle_simulation_E-MLP.png',bbox_inches='tight')

if __name__=="__main__":
    
    #########################################################################
    ##### simulation x with given initial condition and sigma bar ###########
    #########################################################################
    from simulate_tools import simulate_x_with_sigma
    idx_init, length = 0, 3000
    x_init, s_init = x1[idx_init], s1[idx_init]
    x_series, s_series, t_series, fx_series = simulate_x_with_sigma(model_f, x_init, s_init, dt_x, idx_init, s1, length)
    
    plt.figure(figsize=[16,5])
    plt.subplot(1,2,1)
    plt.plot(t_series, x_series, linewidth=.6, label='$X$ generated by Euler method')
    plt.plot(t_series, x1[idx_init:idx_init+length], linewidth=.6, label='$X$ numerical')
    mse1 = np.mean((x_series-x1[idx_init:idx_init+length])**2)
    plt.plot([], [], ' ', label="MSE={:.2e}".format(mse1))
    # plt.ylim(-1,1)
    plt.xlabel('t')
    plt.legend(loc='lower right')
    plt.subplot(1,2,2)
    plt.plot(t_series, fx_series, linewidth=.6, label="$X'$ generated by Euler method")
    plt.plot(t_series, diff_x[idx_init:idx_init+length], linewidth=.6, label="$X'$ numerical")
    # plt.plot(t_series, s1[idx_init:idx_init+length], linewidth=.6, label='$\sigma$ real')
    msef1 = np.mean((x_series-diff_x[idx_init:idx_init+length])**2)
    plt.plot([], [], ' ', label="MSE={:.2e}".format(msef1))
    # plt.ylim(-1.5,1)
    plt.xlabel('t')
    plt.legend(loc='lower right')
    # plt.savefig('./figures/Saddle_generate_x_by_given_sigma_E-MLP.png',bbox_inches='tight')
    
    ##############################
    ####### estimate E-MLP #######
    ##### for table in paper #####
    ##############################
    length = 600
    np.random.seed(1)
    init_idx = np.random.choice(np.arange(10000, x1.shape[0]-length),1000)

    mse1_list, msef1_list = [], []
    for i, idx in enumerate(init_idx):
        x_init, s_init = x1[idx], s1[idx]
        x_series, s_series, t_series, fx_series = simulate_x_with_sigma(model_f, x_init, s_init, dt_x, idx, s1, length)
        
        mse1 = np.average((x_series[:, 0]-x1[idx:idx+length, 0])**2)
        msef1 = np.average((fx_series[:, 0]-diff_x[idx:idx+length, 0])**2)
        
        mse1_list.append(mse1)
        msef1_list.append(msef1)
        
        print(i)

    print("MSE of X: {}".format(np.mean(mse1_list))) ##0.005005750444036425
    print("MSE of X': {}".format(np.mean(msef1_list))) ##0.002502816469516608
    
    
    
    #################################################################
    ###### simulate both x and s by E-MLP with Gaussian noise #######
    #################################################################
    from simulate_tools import simulate_xs_with_GNN
    length = 10000
    idx_init = 0
    dt = 0.001*ks
    
    fig, axes = plt.subplots(1,2,figsize=[16,4])
    for _ in range(3):
        x_init, s_init = [[0.9994]], [[0.503]]
        x_series, s_series, t_series = \
            simulate_xs_with_GNN(model_f, model_H, x_init, s_init, dt, length, stop_threshold=-1)
    
        axes[0].plot(t_series, x_series)
        axes[1].plot(t_series, s_series)
        
    axes[0].set_title('X')
    axes[1].set_title(r'$\bar{\sigma}$')
    # fig.savefig('./figures/Simuation_by_E-MLP_with_Gaussian_noise.png')


    ##################################################################
    ###### simulate both x and s by E-MLP with empirical noise #######
    ##################################################################
    from simulate_tools import simulate_xs_with_EN
    length = 10000
    idx_init = 0
    dt = 0.001*ks
    
    fig, axes = plt.subplots(1,2,figsize=[16,4])
    for _ in range(3):
        x_init, s_init = [[0.9994]], [[0.503]]
        
        if params.data_type=='Saddle_high':
            x_series, s_series, t_series = \
            simulate_xs_with_EN(model_f, model_K, x_init, s_init, dt, length=length, stop_threshold=-1, lamb=0.425)
        elif params.data_type=='Saddle_low':
            x_series, s_series, t_series = \
            simulate_xs_with_EN(model_f, model_K, x_init, s_init, dt, length=length, stop_threshold=-1, lamb=0.427)
            
        axes[0].plot(t_series, x_series)
        axes[1].plot(t_series, s_series)
    
    axes[0].set_title('X')
    axes[1].set_title(r'$\bar{\sigma}$')
    # fig.savefig('./figures/Simuation_by_E-MLP_with_empirical_noise.png')
    
    
    # ########### save data(high noise) ###############
    # np.save('./figures/Saddle_high_part.npy', np.c_[np.cumsum(dt_x), x1, s1])
    # SS = []   #for high noise [5,13,17,9,16,11]
    # for i, seed in enumerate([13,24,21,22,23]):
    # # for i, seed in enumerate([33,34,35,36,37,38]):
    #     np.random.seed(seed)
    #     x_init, s_init = [x1[idx_init]], [s1[idx_init]]
    #     x_series, s_series, t_series = \
    #         simulate_xs_with_EN(model_f, model_K, x_init, s_init, dt, length=length, stop_threshold=-1, lamb=0.427)

    #     SS.append(np.c_[t_series, x_series, s_series])
    #     plt.plot(t_series, x_series, label=seed)
    # plt.legend()
    # np.savez('./figures/Saddle_high_simulations.npz', *SS)
    
    
    # ########### save data(low noise) ###############
    # np.save('./figures/Saddle_low_part.npy', np.c_[np.cumsum(dt_x), x1, s1])
    # length = 20000
    # dt = 0.001*ks
    # SS = []   #for low noise [5,13,17,9,16,11]
    # for i, seed in enumerate([5,13,17,9,16,11]):
    #     np.random.seed(seed)
    #     x_init, s_init = [x1[idx_init]], [s1[idx_init]]
    #     x_series, s_series, t_series = \
    #         simulate_xs_with_EN(model_f, model_K, x_init, s_init, dt, length=length, stop_threshold=-1, lamb=0.425)

    #     SS.append(np.c_[t_series, x_series, s_series])
    #     plt.plot(t_series, x_series, label=seed)
    # plt.legend()
    # np.savez('./figures/Saddle_low_simulations.npz', *SS)
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    ##################
    ###### MMD #######
    ##################
    from misc import mmd
    ### simulate both x and sigma with Gaussian noise, std and mean by NN
    def simulate_xs_with_GNN_irregular(model_f, model_std_mean, x_init, s_init, dt, length, stop_threshold=-20):
        
        x_series, s_series, t_series = x_init, s_init, [np.array([0])]
        for i in range(length-1):
            txs = torch.tensor(np.array([np.r_[np.array([1]),x_series[-1],s_series[-1]]]), dtype=torch.float32).to(device)
            f_numerical = model_f(txs).cpu().detach().numpy()
            
            fx_numerical = f_numerical[:,:-1]
            xx_ = x_series[-1] + fx_numerical*dt[i] ##Euler method
            x_series.append(xx_.flatten())
            
            std_mean = model_std_mean(txs).cpu().detach().numpy()
            std, mean = std_mean[:,0], std_mean[:,1]
            
            fs_numerical = f_numerical[:,[-1]] 
            ss_ = s_series[-1] + fs_numerical*dt[i] + (np.random.randn()*std+mean)*dt[i]**.5 ##Euler method, consider noise is Brownian motion
            s_series.append(ss_.flatten())
            
            t_series.append(t_series[-1]+dt[i])
            
            if xx_.flatten()[0]<stop_threshold: ##for saddle data
                break
        x_series, s_series, t_series = np.array(x_series), np.array(s_series), np.array(t_series)
        return x_series, s_series, t_series
    
    
    length = 256
    num = 100
    # init_ = np.random.choice(np.arange(91200-600),1024)
    mm = np.logical_and(x1[:,0]>-0.05, x1[:,0]<0.05)
    mm[-length:] = False
    init_ = np.random.choice(np.arange(x1.shape[0])[mm], num)
    
    
    x1_train, s1_train = [], []
    for i in range(length):
        x1_train.append(x1[init_+i])
        s1_train.append(s1[init_+i])
    
    x1_train = np.array(x1_train, dtype=np.float32)
    s1_train = np.array(s1_train, dtype=np.float32)
    X_real = np.c_[x1_train,s1_train].transpose(1,0,2)
    

    MMD_GNN = []
    for _ in range(10):
        X_GNN_generate = []
        for l in range(num):
            idx = np.random.choice(init_)
            dt = dt_x[idx:,0]
            x_init, s_init = [x1[idx]], [s1[idx]]
            
            x_series, s_series, t_series = simulate_xs_with_GNN_irregular(model_f, model_H, x_init, s_init, dt, length)
            X_GNN_generate.append(np.c_[x_series, s_series])
            
            if l%100==0:
                print(l)
        
        X_GNN_generate = np.array(X_GNN_generate)
        
        mmd1 = mmd(X_real[:,:,0], X_GNN_generate[:,:,0], sigma=1).item()
        mmd2 = mmd(X_real[:,:,1], X_GNN_generate[:,:,1], sigma=1).item()
        
        MMD_GNN.append([mmd1,mmd2])
        
    print('MMD mean of GNN: ', np.array(MMD_GNN).mean(0))
    print('MMD std of GNN: ', np.array(MMD_GNN).std(0))
    
    
    # plt.plot(x_series[:,:])
    # plt.plot(x1[idx:idx+length,:])
    
    
    
    
    ### simulate both x and sigma with approximated empirical noise(model_eps)
    def simulate_xs_with_EN_irregular(model_f, model_eps, x_init, s_init, dt, length=10000, stop_threshold=-20, lamb=0.427):
        x_series, s_series, t_series = x_init, s_init, [np.array([0])]
         # dt is larger than dt in given data
        for i in range(length-1):
            txs = torch.tensor([np.r_[np.array([1]),x_series[-1],s_series[-1]]], dtype=torch.float32).to(device)
            f_numerical = model_f(txs).cpu().detach().numpy()
            
            fx_numerical = f_numerical[:,:-1]
            xx_ = x_series[-1] + fx_numerical*dt[i] ##Euler method
            x_series.append(xx_.flatten())
        
            obs = torch.tensor([np.r_[x_series[-1],s_series[-1], np.random.rand()]], dtype=torch.float32).to(device)
            eps = model_eps(obs).cpu().detach().numpy().item()
            
            fs_numerical = f_numerical[:,[-1]]
            # fs_numerical = fs_np(1,xx_,ss_)
            ss_ = s_series[-1] + fs_numerical*dt[i] + eps*dt[i]**lamb ##Euler method
            s_series.append(ss_.flatten())
            
            t_series.append(t_series[-1]+dt[i])
                
            if xx_.flatten()[0]<stop_threshold: ##for saddle data
                break
            
        x_series = np.array(x_series)
        s_series = np.array(s_series)
        t_series = np.array(t_series)
        return x_series, s_series, t_series
        
    
    MMD_EN = []
    for _ in range(10):
        X_EN_generate = []
        for l in range(num):
            idx = np.random.choice(init_)
            dt = dt_x[idx:,0]
            x_init, s_init = [x1[idx]], [s1[idx]]
            
            x_series, s_series, t_series = simulate_xs_with_EN_irregular(model_f, model_K, x_init, s_init, dt, length)
            X_EN_generate.append(np.c_[x_series, s_series])
            
            if l%100==0:
                print(l)
    
        X_EN_generate = np.array(X_EN_generate)
        
        mmd1 = mmd(X_real[:,:,0], X_EN_generate[:,:,0], sigma=1).item()
        mmd2 = mmd(X_real[:,:,1], X_EN_generate[:,:,1], sigma=1).item()
        
        MMD_EN.append([mmd1,mmd2])
        

    print('MMD mean of EN: ', np.array(MMD_EN).mean(0))
    print('MMD std of EN: ', np.array(MMD_EN).std(0))
    
    
    # MMD_PI_CGAN = []
    # for _ in range(10):
    #     X_PI_CGAN_generate = []
    #     for l in range(num):
    #         idx = np.random.choice(init_)
    #         x_init, s_init = x1[idx], s1[idx]
    #         x_series, s_series, t_series, fx_series = simulate_x_with_sigma(model_f, x_init, s_init, dt_x, idx, s1, length)
    #         X_PI_CGAN_generate.append(np.c_[x_series, s_series])
            
    #         if l%100==0:
    #             print(l)
    #     X_PI_CGAN_generate = np.array(X_PI_CGAN_generate)
        
    #     mmd1 = mmd(X_real[:,:,0], X_PI_CGAN_generate[:,:,0], sigma=1).item()
    #     mmd2 = mmd(X_real[:,:,1], X_PI_CGAN_generate[:,:,1], sigma=1).item()
        
    #     MMD_PI_CGAN.append([mmd1,mmd2])
            
    # print('MMD mean of PI-CGAN: ', np.array(MMD_PI_CGAN).mean(0))
    # print('MMD std of PI-CGAN: ', np.array(MMD_PI_CGAN).std(0))
    
    
    # X_NeuralSDE = np.load('./figures/NeuralSDE/samples.npy')
    # print('MMD of X1 of Neural SDE: ', mmd(X_real[:,:,0], X_NeuralSDE[:,:,0], sigma=1))
    # print('MMD of X2 of Neural SDE: ', mmd(X_real[:,:,1], X_NeuralSDE[:,:,1], sigma=1))
    # print('MMD of sigma bar of Neural SDE: ', mmd(X_real[:,:,2], X_NeuralSDE[:,:,2], sigma=1))
    